To gain widespread acceptance, Federated Learning (FL) must balance performance, privacy-preservation, and interpretability, particularly in critical fields such as finance and healthcare. As a result, there is a high demand for interpretable FL (IFL) that can address these concerns. IFL is more challenging than current interpretable methods designed for centralized machine learning, primarily due to the invisibility of local data.

## Who Is Interested in Interpretable Federated Learning (IFL)?

Those interested in Interpretable Federated Learning (IFL) include researchers, developers, regulatory agencies, policymakers, civil societies, and others involved in obtaining explanations related to the FL model or the FL training process.

- [ ] For a given Federated Learning (FL) task, the FL server may require an understanding of why a client has chosen specific data samples or features.
- [x] TODO#2, but this one is done !

## Survey Paple

| Paper Name | Journal / Conference | Year |
| --- | --- | --- |
| [Towards Interpretable Federated Learning](https://arxiv.org/abs/2302.13473) | arXiv | 2023 |


## Technical Paper

| Paper Name | Journal / Conference | Year | Code |
| --- | --- | --- | --- |
